{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e00d29d",
   "metadata": {},
   "source": [
    "# COMP5318 Assignment: 490182143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbb2b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images_training.h5', 'labels_training.h5']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.listdir(\"./Input/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2313bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./Input/train/images_training.h5','r') as H:\n",
    "    X_train = np.copy(H['datatrain'])\n",
    "with h5py.File('./Input/train/labels_training.h5','r') as H:\n",
    "    y_train = np.copy(H['labeltrain'])\n",
    "\n",
    "with h5py.File('./Input/test/images_testing.h5','r') as H:\n",
    "    X_test = np.copy(H['datatest'])\n",
    "with h5py.File('./Input/test/labels_testing_2000.h5','r') as H:\n",
    "    y_test = np.copy(H['labeltest'])\n",
    "    \n",
    "# using H['datatest'], H['labeltest'] for test dataset.\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3599afa",
   "metadata": {},
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab88d0b",
   "metadata": {},
   "source": [
    "#### Normalising Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102616a",
   "metadata": {},
   "source": [
    "Our first step towards pre-processing the dataset can be achieved by normalising the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605c5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c43664",
   "metadata": {},
   "source": [
    "#### PCA (100 Components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93559f59",
   "metadata": {},
   "source": [
    "Once we have used our min-max scaler to normalise the input data, we can run PCA for aiming towards a lower runtime for prediction whilst preserving a competent accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38264af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 100)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916beb8",
   "metadata": {},
   "source": [
    "Now that we have transformed the image data with normalisation and PCA of 100 components, we can consider the input data to be pre-processed and ready for being classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b11217",
   "metadata": {},
   "source": [
    "## Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c849d",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5042c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "scores_knn = cross_val_score(clf_knn, X_train, y_train, cv = 10)\n",
    "knn_score = scores_knn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4fc7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552 accuracy for K-Nearest Neighbours Classifier\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.4f accuracy for K-Nearest Neighbours Classifier\" % (knn_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4acabc",
   "metadata": {},
   "source": [
    "### Na誰ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0d5bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_train, y_train)\n",
    "scores_gnb = cross_val_score(clf_gnb, X_train, y_train, cv = 10)\n",
    "gnb_score = scores_gnb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899e8617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7659 accuracy for Na誰ve Bayes Classifier\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.4f accuracy for Na誰ve Bayes Classifier\" % (gnb_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af3a02",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f015ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier(criterion = \"entropy\", random_state = 42)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "scores_dt = cross_val_score(clf_dt, X_train, y_train, cv = 10)\n",
    "dt_score = scores_dt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e728808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7638 accuracy for Decision Tree Classifier\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.4f accuracy for Decision Tree Classifier\" % (dt_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28090c07",
   "metadata": {},
   "source": [
    "## Parameter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fa00d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "KNeighborsClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903e3e6",
   "metadata": {},
   "source": [
    "### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bb04508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8588666666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_params = {\"n_neighbors\" : [3, 5, 7, 9, 11],\n",
    "              \"weights\" : [\"distance\", \"uniform\"],\n",
    "              \"metric\" : [\"minkowski\",\"euclidean\",\"manhattan\"]}\n",
    "knn_gs = GridSearchCV(KNeighborsClassifier(), knn_grid_params, verbose = 1, cv = 10, n_jobs = -1)\n",
    "knn_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a08a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'} 0.8588666666666667\n"
     ]
    }
   ],
   "source": [
    "print(knn_gs.best_params_, knn_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185587d4",
   "metadata": {},
   "source": [
    "Output and save file for kNN using hyper-parameters as it performs the best of all 3 classifiers with and without parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a34fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn_hp = KNeighborsClassifier(n_neighbors = 5, metric = \"manhattan\", weights = \"uniform\")\n",
    "clf_knn_hp.fit(X_train, y_train)\n",
    "predict = clf_knn_hp.predict(X_test)\n",
    "output = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6549d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with h5py.File('./Output/predicted_labels.h5','w') as H:\n",
    "    H.create_dataset('Output',data=output)\n",
    "H.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc36024",
   "metadata": {},
   "source": [
    "### Na誰ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1290f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(), n_jobs=-1,\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.848035...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB().get_params().keys() \n",
    "gnb_grid_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gnb_gs = GridSearchCV(GaussianNB(), gnb_grid_params, verbose = 1, cv = 10, n_jobs = -1)\n",
    "gnb_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f647d9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.0003511191734215131} 0.7680333333333332\n"
     ]
    }
   ],
   "source": [
    "print(gnb_gs.best_params_, gnb_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec7297",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5762c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy']}, verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier().get_params().keys()\n",
    "dt_grid_params = {\"criterion\" : [\"gini\", \"entropy\"]}\n",
    "dt_gs = GridSearchCV(DecisionTreeClassifier(), dt_grid_params, verbose = 1, cv = 10, n_jobs = -1)\n",
    "dt_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f0e5fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'} 0.7603666666666666\n"
     ]
    }
   ],
   "source": [
    "print(dt_gs.best_params_, dt_gs.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
